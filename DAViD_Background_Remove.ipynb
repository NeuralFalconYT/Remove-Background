{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/NeuralFalconYT/Remove-Background.git\n",
        "%cd ./Remove-Background\n",
        "!apt install aria2 -y\n",
        "!aria2c -x 16 -s 16 \"https://facesyntheticspubwedata.z6.web.core.windows.net/iccv-2025/models/foreground-segmentation-model-vitb16_384.onnx\"\n",
        "!aria2c -x 16 -s 16 \"https://facesyntheticspubwedata.z6.web.core.windows.net/iccv-2025/models/foreground-segmentation-model-vitl16_384.onnx\"\n",
        "\n",
        "!pip install onnxruntime-gpu\n",
        "# !pip install onnxruntime-gpu==1.22.0\n",
        "!pip install numpy==2.2.6\n",
        "!pip install onnx==1.18.0\n",
        "!pip install opencv-python==4.12.0.88\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RRNNomg0Xbu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Remove-Background\n",
        "from soft_foreground_segmenter import SoftForegroundSegmenter\n",
        "import cv2\n",
        "import numpy as np\n",
        "foreground_model = \"foreground-segmentation-model-vitl16_384.onnx\"\n",
        "foreground_segmenter = SoftForegroundSegmenter(onnx_model=foreground_model)\n",
        "\n",
        "def apply_green_screen(image_path: str, save_path: str = None):\n",
        "    \"\"\"\n",
        "    Replaces the background of the input image with green using a segmentation model.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        segmenter (SoftForegroundSegmenter): Initialized segmentation model.\n",
        "        save_path (str, optional): If provided, saves the result to this path.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The green screen composited image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load image with alpha if available\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "\n",
        "    # Remove transparency if present\n",
        "    if image.shape[2] == 4:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "    # Convert to RGB for the model\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Get segmentation mask\n",
        "    mask = foreground_segmenter.estimate_foreground_segmentation(image_rgb)\n",
        "\n",
        "    # Normalize and convert mask to 0-255 uint8\n",
        "    if mask.max() <= 1.0:\n",
        "        mask = (mask * 255).astype(np.uint8)\n",
        "    else:\n",
        "        mask = mask.astype(np.uint8)\n",
        "\n",
        "    if mask.ndim == 2:\n",
        "        mask_gray = mask\n",
        "    elif mask.shape[2] == 1:\n",
        "        mask_gray = mask[:, :, 0]\n",
        "    else:\n",
        "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    _, binary_mask = cv2.threshold(mask_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Create green background\n",
        "    green_bg = np.full_like(image_rgb, (0, 255, 0), dtype=np.uint8)\n",
        "\n",
        "    # Create 3-channel mask\n",
        "    mask_3ch = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Composite: foreground from image, background as green\n",
        "    output_rgb = np.where(mask_3ch == 255, image_rgb, green_bg)\n",
        "\n",
        "    # Convert back to BGR for OpenCV\n",
        "    output_bgr = cv2.cvtColor(output_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Save if path is given\n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, output_bgr)\n",
        "\n",
        "    return output_bgr\n",
        "\n",
        "\n",
        "def create_transparent_foreground(image_path: str, save_path: str = None):\n",
        "    \"\"\"\n",
        "    Removes the background from an image and saves it as a transparent PNG.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        segmenter (SoftForegroundSegmenter): Initialized segmentation model.\n",
        "        save_path (str, optional): Path to save the transparent image.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: RGBA image with transparent background.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "\n",
        "    # Handle alpha\n",
        "    if image.shape[2] == 4:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "    # Convert to RGB for model\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Get mask from segmenter\n",
        "    mask = foreground_segmenter.estimate_foreground_segmentation(image_rgb)\n",
        "\n",
        "    # Normalize and convert mask to uint8\n",
        "    if mask.max() <= 1.0:\n",
        "        mask = (mask * 255).astype(np.uint8)\n",
        "    else:\n",
        "        mask = mask.astype(np.uint8)\n",
        "\n",
        "    # Ensure grayscale\n",
        "    if mask.ndim == 3 and mask.shape[2] == 3:\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold to binary alpha mask\n",
        "    _, alpha = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Convert original image to RGB (in case BGR)\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Stack RGB and alpha\n",
        "    rgba_image = np.dstack((rgb_image, alpha))\n",
        "\n",
        "    # Save if requested\n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, cv2.cvtColor(rgba_image, cv2.COLOR_RGBA2BGRA))  # For OpenCV\n",
        "\n",
        "    return rgba_image\n"
      ],
      "metadata": {
        "id": "i1V_O9i7fqd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import glob\n",
        "from tqdm.auto import tqdm\n",
        "import uuid\n",
        "import re\n",
        "gpu = True\n",
        "\n",
        "def get_sorted_paths(directory, extension=\"png\"):\n",
        "    \"\"\"\n",
        "    Returns full paths of all images with the given extension, sorted by filename (without extension).\n",
        "    \"\"\"\n",
        "    extension = extension.lstrip(\".\").lower()\n",
        "    pattern = os.path.join(directory, f\"*.{extension}\")\n",
        "    files = glob.glob(pattern)\n",
        "    files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "    return files\n",
        "\n",
        "\n",
        "def extract_all_frames_ffmpeg_gpu(video_path, output_dir=\"frames\", extension=\"png\", use_gpu=True):\n",
        "    \"\"\"\n",
        "    Extracts all frames from a video using ffmpeg, with optional GPU acceleration.\n",
        "    Returns a sorted list of full paths to the extracted frames.\n",
        "    \"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    extension = extension.lstrip(\".\")\n",
        "    output_pattern = os.path.join(output_dir, f\"%05d.{extension}\")\n",
        "\n",
        "    command = [\n",
        "        \"ffmpeg\", \"-i\", video_path, output_pattern\n",
        "    ]\n",
        "    if use_gpu:\n",
        "        command.insert(1, \"cuda\")\n",
        "        command.insert(1, \"-hwaccel\")\n",
        "\n",
        "    print(\"Running command:\", \" \".join(command))\n",
        "    subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    return get_sorted_paths(output_dir, extension)\n",
        "\n",
        "\n",
        "\n",
        "def green_screen_batch(frames, output_dir=\"green_screen_frames\"):\n",
        "    \"\"\"\n",
        "    Applies green screen background to a batch of frames and saves the results.\n",
        "\n",
        "    Args:\n",
        "        frames (List[str]): List of image paths.\n",
        "        output_dir (str): Directory to save green-screened output.\n",
        "    \"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    green_screen_frames=[]\n",
        "    for frame in tqdm(frames, desc=\"Processing green screen frames\"):\n",
        "        save_image_path=os.path.join(output_dir, os.path.basename(frame))\n",
        "        result = apply_green_screen(\n",
        "            image_path=frame,\n",
        "            save_path=save_image_path\n",
        "        )\n",
        "        green_screen_frames.append(save_image_path)\n",
        "    return green_screen_frames\n",
        "\n",
        "\n",
        "def green_screen_video_maker(original_video, green_screen_frames, batch_size=100):\n",
        "    \"\"\"\n",
        "    Creates video chunks from green screen frames based on original video's properties.\n",
        "\n",
        "    Args:\n",
        "        original_video (str): Path to the original video file (to read FPS, size).\n",
        "        green_screen_frames (List[str]): List of green screen frame paths.\n",
        "        batch_size (int): Number of frames per chunked video.\n",
        "    \"\"\"\n",
        "    temp_folder = \"temp_video\"\n",
        "    if os.path.exists(temp_folder):\n",
        "        shutil.rmtree(temp_folder)\n",
        "    os.makedirs(temp_folder, exist_ok=True)\n",
        "\n",
        "    # Get video info from original video\n",
        "    cap = cv2.VideoCapture(original_video)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "\n",
        "    total_frames = len(green_screen_frames)\n",
        "    num_chunks = (total_frames + batch_size - 1) // batch_size  # Ceiling division\n",
        "\n",
        "    for chunk_idx in tqdm(range(num_chunks), desc=\"Processing video chunks\"):\n",
        "        chunk_path = os.path.join(temp_folder, f\"{chunk_idx+1}.mp4\")\n",
        "        out = cv2.VideoWriter(chunk_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "        start_idx = chunk_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, total_frames)\n",
        "\n",
        "        for frame_path in green_screen_frames[start_idx:end_idx]:\n",
        "            frame = cv2.imread(frame_path)\n",
        "            frame = cv2.resize(frame, (width, height))  # Ensure matching resolution\n",
        "            out.write(frame)\n",
        "\n",
        "        out.release()\n",
        "\n",
        "\n",
        "\n",
        "def merge_video_chunks(output_path=\"final_video.mp4\", temp_folder=\"temp_video\", use_gpu=True):\n",
        "    \"\"\"\n",
        "    Merges all video chunks from temp_folder into a final single video.\n",
        "    \"\"\"\n",
        "    os.makedirs(\"./results\", exist_ok=True)\n",
        "    output_path = f\"../results/{output_path}\"  # relative to temp_folder\n",
        "    file_list_path = os.path.join(temp_folder, \"chunks.txt\")\n",
        "    chunk_files=sorted(\n",
        "            [f for f in os.listdir(temp_folder) if f.lower().endswith(\"mp4\")],\n",
        "            key=lambda x: int(os.path.splitext(x)[0])\n",
        "        )\n",
        "\n",
        "    with open(file_list_path, \"w\") as f:\n",
        "        for chunk in chunk_files:\n",
        "            f.write(f\"file '{chunk}'\\n\")  # ✅ No './' prefix\n",
        "\n",
        "    ffmpeg_cmd = [\"ffmpeg\", \"-y\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"chunks.txt\"]\n",
        "\n",
        "    if use_gpu:\n",
        "        ffmpeg_cmd += [\"-c:v\", \"h264_nvenc\", \"-preset\", \"fast\"]\n",
        "    else:\n",
        "        ffmpeg_cmd += [\"-c\", \"copy\"]\n",
        "\n",
        "    ffmpeg_cmd.append(output_path)\n",
        "\n",
        "    # ✅ Run from inside temp_folder, so chunks.txt and mp4 files are local\n",
        "    subprocess.run(ffmpeg_cmd, cwd=temp_folder, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "\n",
        "def extract_audio_from_video(video_path, output_audio_path=\"output_audio.wav\", format=\"wav\", sample_rate=16000, channels=1):\n",
        "    \"\"\"\n",
        "    Extracts audio from a video file using ffmpeg.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the input video file.\n",
        "        output_audio_path (str): Path to save the extracted audio (e.g., .wav or .mp3).\n",
        "        format (str): 'wav' or 'mp3'\n",
        "        sample_rate (int): Sampling rate in Hz (e.g., 16000 for ASR models)\n",
        "        channels (int): Number of audio channels (1=mono, 2=stereo)\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(os.path.dirname(output_audio_path) or \".\", exist_ok=True)\n",
        "\n",
        "    # Build ffmpeg command\n",
        "    if format.lower() == \"wav\":\n",
        "        command = [\n",
        "            \"ffmpeg\", \"-y\",               # Overwrite output\n",
        "            \"-i\", video_path,            # Input video\n",
        "            \"-vn\",                       # Disable video\n",
        "            \"-ac\", str(channels),        # Audio channels (1 = mono)\n",
        "            \"-ar\", str(sample_rate),     # Audio sample rate\n",
        "            \"-acodec\", \"pcm_s16le\",      # WAV codec\n",
        "            output_audio_path\n",
        "        ]\n",
        "    elif format.lower() == \"mp3\":\n",
        "        command = [\n",
        "            \"ffmpeg\", \"-y\",\n",
        "            \"-i\", video_path,\n",
        "            \"-vn\",\n",
        "            \"-ac\", str(channels),\n",
        "            \"-ar\", str(sample_rate),\n",
        "            \"-acodec\", \"libmp3lame\",     # MP3 codec\n",
        "            output_audio_path\n",
        "        ]\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported format. Use 'wav' or 'mp3'.\")\n",
        "\n",
        "    # Run command silently\n",
        "    subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "def add_audio(video_path, audio_path, output_path, use_gpu=False):\n",
        "    \"\"\"\n",
        "    Replaces the audio of a video with a new audio track.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        audio_path (str): Path to the audio file.\n",
        "        output_path (str): Path where the final video will be saved.\n",
        "        use_gpu (bool): If True, use GPU-accelerated video encoding.\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    command = [\n",
        "        \"ffmpeg\", \"-y\",                     # Overwrite without asking\n",
        "        \"-i\", video_path,                  # Input video\n",
        "        \"-i\", audio_path,                  # Input audio\n",
        "        \"-map\", \"0:v:0\",                   # Use video from first input\n",
        "        \"-map\", \"1:a:0\",                   # Use audio from second input\n",
        "        \"-shortest\"                        # Trim to the shortest stream (audio/video)\n",
        "    ]\n",
        "\n",
        "    if use_gpu:\n",
        "        command += [\"-c:v\", \"h264_nvenc\", \"-preset\", \"fast\"]\n",
        "    else:\n",
        "        command += [\"-c:v\", \"copy\"]\n",
        "\n",
        "    command += [\"-c:a\", \"aac\", \"-b:a\", \"192k\", output_path]\n",
        "\n",
        "    subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "\n",
        "\n",
        "def remove_background_from_video(uploaded_video_path):\n",
        "    # 🔁 Generate a single UUID to use for all related files\n",
        "    uid = uuid.uuid4().hex[:8].upper()\n",
        "\n",
        "    # Define all output paths using that UUID\n",
        "    base_name = \"video_process\"  # You can customize this if needed\n",
        "    temp_video_path = f\"./results/{base_name}_chunks_{uid}.mp4\"\n",
        "    audio_path = f\"./results/{base_name}_audio_{uid}.wav\"\n",
        "    final_output_path = f\"./results/{base_name}_final_{uid}.mp4\"\n",
        "\n",
        "    # Step 1: Extract frames\n",
        "    frames = extract_all_frames_ffmpeg_gpu(\n",
        "        video_path=uploaded_video_path,\n",
        "        output_dir=\"frames\",\n",
        "        extension=\"png\",\n",
        "        use_gpu=gpu\n",
        "    )\n",
        "\n",
        "    # Step 2: Remove background (green screen)\n",
        "    green_screen_frames = green_screen_batch(frames)\n",
        "\n",
        "    # Step 3: Rebuild video from frames\n",
        "    green_screen_video_maker(uploaded_video_path, green_screen_frames, batch_size=100)\n",
        "\n",
        "    # Step 4: Merge video chunks\n",
        "    merge_video_chunks(output_path=os.path.basename(temp_video_path), use_gpu=gpu)\n",
        "\n",
        "    # Step 5: Extract original audio\n",
        "    extract_audio_from_video(uploaded_video_path, output_audio_path=audio_path)\n",
        "\n",
        "    # Step 6: Add audio back\n",
        "    add_audio(\n",
        "        video_path=temp_video_path,\n",
        "        audio_path=audio_path,\n",
        "        output_path=final_output_path,\n",
        "        use_gpu=True\n",
        "    )\n",
        "\n",
        "    return os.path.abspath(final_output_path)\n"
      ],
      "metadata": {
        "id": "flL-sQRZhAFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path=remove_background_from_video(\"/content/video.mp4\")"
      ],
      "metadata": {
        "id": "W1fYvKtv-0Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(save_path)"
      ],
      "metadata": {
        "id": "a30l_1IEA9Pm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}